{
  "3": {
    "inputs": {
      "seed": 682779852533864,
      "steps": 6,
      "cfg": 1,
      "sampler_name": "euler",
      "scheduler": "beta",
      "denoise": 1,
      "model": [
        "54",
        0
      ],
      "positive": [
        "50",
        0
      ],
      "negative": [
        "50",
        1
      ],
      "latent_image": [
        "50",
        2
      ]
    },
    "class_type": "KSampler",
    "_meta": {
      "title": "KSampler"
    }
  },
  "4": {
    "inputs": {
      "lora_name": "DetailEnhancerV1.safetensors",
      "strength_model": 0.4000000000000001,
      "model": [
        "314",
        0
      ]
    },
    "class_type": "LoraLoaderModelOnly",
    "_meta": {
      "title": "LoraLoaderModelOnly(detail enhancer)"
    }
  },
  "6": {
    "inputs": {
      "text": "the man is singing and dancing",
      "clip": [
        "129",
        0
      ]
    },
    "class_type": "CLIPTextEncode",
    "_meta": {
      "title": "CLIP Text Encode (Positive Prompt)"
    }
  },
  "7": {
    "inputs": {
      "text": "色调艳丽，过曝，静态，细节模糊不清，字幕，风格，作品，画作，画面，静止，整体发灰，最差质量，低质量，JPEG压缩残留，丑陋的，残缺的，多余的手指，画得不好的手部，画得不好的脸部，畸形的，毁容的，形态畸形的肢体，手指融合，静止不动的画面，杂乱的背景，三条腿，背景人很多",
      "clip": [
        "129",
        0
      ]
    },
    "class_type": "CLIPTextEncode",
    "_meta": {
      "title": "CLIP Text Encode (Negative Prompt)"
    }
  },
  "8": {
    "inputs": {
      "samples": [
        "3",
        0
      ],
      "vae": [
        "305",
        0
      ]
    },
    "class_type": "VAEDecode",
    "_meta": {
      "title": "VAE Decode"
    }
  },
  "30": {
    "inputs": {
      "frame_rate": 16,
      "loop_count": 0,
      "filename_prefix": "FusionXi2v/FusionX",
      "format": "video/h264-mp4",
      "pix_fmt": "yuv420p",
      "crf": 19,
      "save_metadata": true,
      "trim_to_audio": false,
      "pingpong": false,
      "save_output": true,
      "images": [
        "8",
        0
      ]
    },
    "class_type": "VHS_VideoCombine",
    "_meta": {
      "title": "Q8 WITH FUSION X"
    }
  },
  "49": {
    "inputs": {
      "clip_name": "clip_vision_h.safetensors"
    },
    "class_type": "CLIPVisionLoader",
    "_meta": {
      "title": "Load CLIP Vision"
    }
  },
  "50": {
    "inputs": {
      "width": 832,
      "height": 480,
      "length": 81,
      "batch_size": 1,
      "positive": [
        "6",
        0
      ],
      "negative": [
        "7",
        0
      ],
      "vae": [
        "305",
        0
      ],
      "clip_vision_output": [
        "51",
        0
      ],
      "start_image": [
        "52",
        0
      ]
    },
    "class_type": "WanImageToVideo",
    "_meta": {
      "title": "WanImageToVideo"
    }
  },
  "51": {
    "inputs": {
      "crop": "none",
      "clip_vision": [
        "49",
        0
      ],
      "image": [
        "52",
        0
      ]
    },
    "class_type": "CLIPVisionEncode",
    "_meta": {
      "title": "CLIP Vision Encode"
    }
  },
  "52": {
    "inputs": {
      "image": "4b629bef-c938-422a-9a06-d0c7ebcc7141.png"
    },
    "class_type": "LoadImage",
    "_meta": {
      "title": "Load Image"
    }
  },
  "54": {
    "inputs": {
      "shift": 1.0000000000000002,
      "model": [
        "111",
        0
      ]
    },
    "class_type": "ModelSamplingSD3",
    "_meta": {
      "title": "ModelSamplingSD3"
    }
  },
  "108": {
    "inputs": {
      "sage_attention": "auto",
      "model": [
        "4",
        0
      ]
    },
    "class_type": "PathchSageAttentionKJ",
    "_meta": {
      "title": "Patch Sage Attention KJ"
    }
  },
  "111": {
    "inputs": {
      "enable_fp16_accumulation": true,
      "model": [
        "108",
        0
      ]
    },
    "class_type": "ModelPatchTorchSettings",
    "_meta": {
      "title": "Model Patch Torch Settings"
    }
  },
  "129": {
    "inputs": {
      "clip_name": "umt5-xxl-encoder-Q8_0.gguf",
      "type": "wan"
    },
    "class_type": "CLIPLoaderGGUF",
    "_meta": {
      "title": "CLIPLoader (GGUF)"
    }
  },
  "295": {
    "inputs": {
      "unet_name": "fusion/Wan2.1_I2V_14B_FusionX-Q8_0.gguf"
    },
    "class_type": "UnetLoaderGGUF",
    "_meta": {
      "title": "Unet Loader (GGUF)"
    }
  },
  "305": {
    "inputs": {
      "vae_name": "wan_2.1_vae.safetensors"
    },
    "class_type": "VAELoader",
    "_meta": {
      "title": "Load VAE"
    }
  },
  "314": {
    "inputs": {
      "lora_name": "lightx2v_T2V_14B_cfg_step_distill_v2_lora_rank32_bf16.safetensors",
      "strength_model": 1.0000000000000002,
      "model": [
        "295",
        0
      ]
    },
    "class_type": "LoraLoaderModelOnly",
    "_meta": {
      "title": "LoraLoaderModelOnly"
    }
  }
}